# This yaml file contains operators that are unsupported with openvino backend and 
# will use portable kernels for fall back

- op: _cdist_forward.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::_cdist_forward_out

- op: _pdist_forward.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::_pdist_forward_out

- op: alias_copy.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::alias_copy_out

- op: any.all_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::any_all_out

- op: any.dims_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::any_dims_out

- op: atan.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::atan_out

- op: atan2.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::atan2_out

- op: bitwise_or.Scalar_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::bitwise_or_Scalar_out

- op: bitwise_xor.Scalar_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::bitwise_xor_Scalar_out

- op: clamp.Tensor_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::clamp_tensor_out

- op: convolution_backward.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::convolution_backward_out

- op: detach_copy.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::detach_copy_out

- op: diagonal_copy.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::diagonal_copy_out

- op: expm1.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::expm1_out

- op: floor_divide.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::floor_divide_out

- op: index_put.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::index_put_out

- op: logical_and.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::logical_and_out

- op: logical_or.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::logical_or_out

- op: logical_xor.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::logical_xor_out

- op: logit.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::logit_out

- op: masked_scatter.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::masked_scatter_out

- op: masked_select.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::masked_select_out

- op: narrow_copy.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::narrow_copy_out

- op: nonzero.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::nonzero_out

- op: pixel_shuffle.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::pixel_shuffle_out

- op: pixel_unshuffle.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::pixel_unshuffle_out

- op: prod.int_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::prod_int_out

- op: prod.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::prod_out

- op: remainder.Tensor_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::remainder_Tensor_out

- op: remainder.Scalar_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::remainder_Scalar_out

- op: repeat_interleave.Tensor_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::repeat_interleave_Tensor_out

- op: reflection_pad1d.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::reflection_pad1d_out

- op: reflection_pad3d.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::reflection_pad3d_out

- op: replication_pad1d.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::replication_pad1d_out

- op: replication_pad2d.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::replication_pad2d_out

- op: replication_pad3d.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::replication_pad3d_out

- op: round.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::round_out

- op: scatter_add.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::scatter_add_out

- op: split_copy.Tensor_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::split_copy_Tensor_out

- op: squeeze_copy.dim_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::squeeze_copy_dim_out

- op: sub.Scalar_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::sub_scalar_out

- op: t_copy.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::t_copy_out

- op: transpose_copy.int_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::transpose_copy_int_out

- op: trunc.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::trunc_out

- op: unbind_copy.int_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::unbind_copy_int_out

- op: upsample_bilinear2d.vec_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::upsample_bilinear2d_vec_out

- func: dim_order_ops::_empty_dim_order.out(int[] size, *, int[]? dim_order=None, Tensor(a!) out) -> Tensor(a!)
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::_empty_dim_order_out

- func: dim_order_ops::_to_dim_order_copy.out(Tensor self, *, bool non_blocking=False, int[]? dim_order=None, Tensor(a!) out) -> Tensor(a!)
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::_to_dim_order_copy_out
